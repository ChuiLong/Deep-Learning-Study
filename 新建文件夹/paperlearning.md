# cs230 DeepLearning

## Part Ⅳ 卷积神经网络CNN
Example 1 ：边缘检测：区分从暗到亮 再从亮到暗的边缘

介于中间的值 像-10 反映了过滤器捕捉到了 左边正边界的一部分和右边负边界的一部分 因此混合在一起 从而得到介于两者之间的值 如果这是一个非常大的图片 比方说这是一个1000乘1000的图片 同样是棋盘形式 那么就不会有这些元素为10的过渡区域 这些过渡值相对于 图片的大小会非常小

Sobel kernal 强化中间的值，往往可以自己学习kernal参数
Valid卷积和 same卷积

通常在计算机视觉(computer vision)领域 f基本上是使用奇数 事实上几乎永远是奇数<br />并且你很少看到偶数大小的 计算机视觉使用的过滤器 并且我想有两个原因导致这个现象 一是如果f是偶数 你会需要一些不对称的填充 所以只有当f是奇数时 这种same卷积会产生 在四周有相同的维度的一个自然的填充区域 而不是在左边多填充在右边少填充 或者别的不对称的填充 其次当你有一个奇数大小的过滤器 比如3x3或者5x5 这样这可以有一个中心位置 有时候在计算机视觉领域 有一个特殊点是很好的 有一个这样的像素是很好的 你可以称之为中心像素 这样你就可以描述你过滤器的位置

多通道卷积涉及到“立方体”的比喻概念

### 卷积神经网络
了解其结构、一对一卷积可以缩小通道数，池化操作（通常不认为是一个卷积层，因为没有需要训练的参数）可以缩小宽和高

### Inception Network is important
事实上是通过增加Bottleneck层来减少计算资源的消耗（瓶颈卷积）


### Mobile Net
轻量化的计算模型

Depthwise卷积运算（深度可分离） 成本更小

# Paper Ⅰ  Deep Residual Learning
## 概念部分
**问题**： 随着网络深度的增加，准确率达到饱和然后迅速退化
**网络退化概念**：神经网络随着层数加深，首先训练准确率会逐渐趋于饱和；若层数继续加深，反而训练准确率下降，效果不好了，而这种下降不是由过拟合造成的（因为如果是过拟合的话，训练时误差应该很低而测试时很高）。
**Q：为啥会出现网络退化？**
由于非线性激活函数Relu的存在，每次输入到输出的过程都几乎是不可逆的，这也造成了许多不可逆的信息损失。一个特征的一些有用的信息损失了，得到的结果肯定不尽人意。说通俗一点就是中间商赚差价。层数增多之后，信息在中间层损失掉了。



解决深度神经网络随着层数增加，复杂性增加，模型的预测准确率反而下降的问题。基本方法是使用了一个没有参数的快捷链接。若最优的映射是恒等映射，则将残差逼近为 0 会比用一堆非线性层去拟合恒等映射更容易。

存在着一个交换论证：无法找到一个比使用恒等映射的方法更优秀或至少相等的算法。

因此，与其期望堆叠层去逼近 $H ( x )$，我们明确要求这些层去逼近残差函数：

$F ( x ) : = H ( x ) − x$


于是，原始函数可重写为：

$H ( x ) = F ( x ) + x$

论文的一个主要观点是，如果最优函数更接近恒等映射而不是零映射，那么基于恒等映射进行微调比从零开始学习新函数更容易实现优化。

![](./Pic1.png "模型架构")

$$y=F(x,\{W_i\})+x \tag 1$$

是优化的目标函数

在公式 $(1)$ 中，$x$和 $F$ 的维度必须一致。如果维度不一致（例如在改变输入/输出通道时），我们可以通过快捷连接添加一个线性映射$W_s$来匹配维度。

当维度发生变化（图 3 中的虚线快捷路径）时，我们考虑两种处理方式：

- 选项 A：快捷路径仍执行恒等映射，对维度扩展部分进行零填充（zero-padding）。该方式不引入额外参数；
- 选项 B：使用公式 (2) 中的投影映射来匹配维度（通过 1 × 1卷积实现）：
$$y = F ( x , \{ W i \} ) + W_s x \tag 2$$

无论哪种方式，当快捷路径跨越不同尺寸的特征图时，其操作都采用步幅为 2 来实现下采样。以上符号同样适用于卷积层。

我们在 ImageNet 上的实现遵循了 [21, 40] 中的做法。图像会被缩放，其较短边随机采样于 [256, 480] 范围内进行尺度增强（scale augmentation）[40]。然后从图像或其水平翻转版本中随机裁剪出一个 224×224 的区域，并减去每个像素的均值 [21]。我们使用了 [21] 中的标准颜色增强方法。

我们采用了批归一化（Batch Normalization, BN）[16]，在每个卷积层之后、激活函数之前进行，遵循 [16] 的做法。权重初始化采用 [12] 的方法，所有的 plain/residual 网络都是从头开始训练的。

我们使用 SGD 优化器，mini-batch 大小为 256。初始学习率设为 0.1，当误差不再下降时将学习率除以 10。模型最多训练 60 × 10⁴ 次迭代。权重衰减为 0.0001，动量为 0.9。我们没有使用 dropout [13]，这也是 [16] 中的实践。

在测试阶段，为了做对比研究，我们采用标准的 10-crop 测试方法 [21]。为了获得最佳结果，我们采用了 [40, 12] 中提出的全卷积形式（fully-convolutional form），并在多个尺度上对得分进行平均（图像的较短边被缩放到 {224, 256, 384, 480, 640} 这些值中）。

在表 3 中，我们比较了三种选择：

- A：在维度增加时使用零填充，所有 shortcut 都是无参数的（与表 2 和图 4 右相同）；
- B：在维度增加时使用投影 shortcut，其他 shortcut 为恒等映射；
- C：所有 shortcut 都使用投影。

表 3 显示这三种方案的性能都远优于 plain 网络。B 略优于 A，我们认为这是因为 A 中的零填充部分并没有参与残差学习。C 略优于 B，我们认为是因为 B 中使用了 13 个投影 shortcut，引入了额外的参数。但 A/B/C 三者之间差距很小，说明投影 shortcut 并非解决退化问题的关键。

因此，为了减少内存、时间复杂度和模型大小，在后续实验中我们不再使用选项 C。特别地，在接下来的瓶颈结构（bottleneck architectures） 中，恒等 shortcut 是非常重要的，它们不会增加复杂度。

![](./6bd5daa09c3d4d44a37c61567956b358.png "一个很有意思的图")

**Bottleneck**主要用在ResNet50及以上的网络结构，与BasicBlock不同的是这里有 3 个卷积，分别为 1\*1，3\*3，1\*1大小的卷积核，分别用于压缩维度、卷积处理、恢复维度。
这里的通道数是变化的，1\*1卷积层的作用就是用于改变特征图的通数，使得可以和恒等映射x相叠加，另外这里的1*1卷积层改变维度的很重要的一点是可以降低网络参数量，这也是为什么更深层的网络采用BottleNeck而不是BasicBlock的原因。

![](./f22a20a6ee8dd82943e122ad054e576b.png "bottleneck")

## 实验部分
![](./PixPin_2025-06-30_16-53-47.png)